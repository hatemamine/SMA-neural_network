{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsulNet10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hatemamine/impact-Of-Image-Colourspace-On-deep-learning-Convolution-Neural-Networks-Performance/blob/master/CapsulNet10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I49o2tWkIfiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To ensure that your GPU is visible by Keras, run following code:\n",
        "\n",
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPSFkRqgEdbz",
        "colab_type": "code",
        "outputId": "9507bed1-40f3-49e7-862c-35060ceb2197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3056
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "from keras import activations\n",
        "from keras import utils\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler ,ReduceLROnPlateau\n",
        "import numpy as np\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 40:\n",
        "        lr *= 0.5\n",
        "    elif epoch > 30:\n",
        "        lr *= 0.5\n",
        "    elif epoch > 18:\n",
        "        lr *= 0.25\n",
        "    elif epoch > 11:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "# the squashing function.\n",
        "# we use 0.5 in stead of 1 in hinton's paper.\n",
        "# if 1, the norm of vector will be zoomed out.\n",
        "# if 0.5, the norm will be zoomed in while original norm is less than 0.5\n",
        "# and be zoomed out while original norm is greater than 0.5.\n",
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "\n",
        "# define our own softmax function instead of K.softmax\n",
        "# because K.softmax can not specify axis.\n",
        "def softmax(x, axis=-1):\n",
        "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "\n",
        "# define the margin loss like hinge loss\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
        "\n",
        "\n",
        "class Capsule(Layer):\n",
        "    \"\"\"A Capsule Implement with Pure Keras\n",
        "    There are two vesions of Capsule.\n",
        "    One is like dense layer (for the fixed-shape input),\n",
        "    and the other is like timedistributed dense (for various length input).\n",
        "\n",
        "    The input shape of Capsule must be (batch_size,\n",
        "                                        input_num_capsule,\n",
        "                                        input_dim_capsule\n",
        "                                       )\n",
        "    and the output shape is (batch_size,\n",
        "                             num_capsule,\n",
        "                             dim_capsule\n",
        "                            )\n",
        "\n",
        "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
        "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 share_weights=True,\n",
        "                 activation='squash',\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(1, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(input_num_capsule, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
        "        but replace b = b + <u,v> with b = <u,v>.\n",
        "\n",
        "        This change can improve the feature representation of Capsule.\n",
        "\n",
        "        However, you can replace\n",
        "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        with\n",
        "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        to realize a standard routing.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, input_num_capsule,\n",
        "                                self.num_capsule, self.dim_capsule))\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
        "            if i < self.routings - 1:\n",
        "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
        "                if K.backend() == 'theano':\n",
        "                    o = K.sum(o, axis=1)\n",
        "\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# A common Conv2D model\n",
        "input_image = Input(shape=(None, None, 3))\n",
        "x = Conv2D(64, (3, 3), activation='relu')(input_image)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "#x = AveragePooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "\n",
        "\n",
        "\"\"\"now we reshape it as (batch_size, input_num_capsule, input_dim_capsule)\n",
        "then connect a Capsule layer.\n",
        "\n",
        "the output of final model is the lengths of 10 Capsule, whose dim=16.\n",
        "\n",
        "the length of Capsule is the proba,\n",
        "so the problem becomes a 10 two-classification problem.\n",
        "\"\"\"\n",
        "\n",
        "x = Reshape((-1, 128))(x)\n",
        "capsule = Capsule(10, 16, 3, True)(x)\n",
        "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
        "model = Model(inputs=input_image, outputs=output)\n",
        "\n",
        "# we use a margin loss\n",
        "model.compile(loss=margin_loss, optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n",
        "model.summary()\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=2,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [lr_reducer, lr_scheduler ]\n",
        "# we can compare the performance with or without data augmentation\n",
        "data_augmentation = True\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_test, y_test),\n",
        "        shuffle=True , callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by dataset std\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in 0 to 180 degrees\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally\n",
        "        height_shift_range=0.1,  # randomly shift images vertically\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(\n",
        "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_test, y_test),\n",
        "        callbacks=callbacks , steps_per_epoch=391)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "reshape_11 (Reshape)         (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "capsule_11 (Capsule)         (None, 10, 16)            20480     \n",
            "_________________________________________________________________\n",
            "lambda_11 (Lambda)           (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 280,640\n",
            "Trainable params: 280,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.4566 - acc: 0.3058 - val_loss: 0.3985 - val_acc: 0.3874\n",
            "Epoch 2/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.3777 - acc: 0.4453 - val_loss: 0.3564 - val_acc: 0.4827\n",
            "Epoch 3/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.3390 - acc: 0.5212 - val_loss: 0.3306 - val_acc: 0.5409\n",
            "Epoch 4/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.3123 - acc: 0.5714 - val_loss: 0.2924 - val_acc: 0.5933\n",
            "Epoch 5/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.2913 - acc: 0.6061 - val_loss: 0.2924 - val_acc: 0.5929\n",
            "Epoch 6/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.2800 - acc: 0.6251 - val_loss: 0.2719 - val_acc: 0.6340\n",
            "Epoch 7/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.2657 - acc: 0.6499 - val_loss: 0.2600 - val_acc: 0.6474\n",
            "Epoch 8/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.2556 - acc: 0.6649 - val_loss: 0.2545 - val_acc: 0.6546\n",
            "Epoch 9/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.2502 - acc: 0.6743 - val_loss: 0.2487 - val_acc: 0.6640\n",
            "Epoch 10/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.2413 - acc: 0.6890 - val_loss: 0.2497 - val_acc: 0.6640\n",
            "Epoch 11/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.2368 - acc: 0.6965 - val_loss: 0.2427 - val_acc: 0.6778\n",
            "Epoch 12/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.2297 - acc: 0.7084 - val_loss: 0.2352 - val_acc: 0.6886\n",
            "Epoch 13/50\n",
            "Learning rate:  0.0001\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.2082 - acc: 0.7412 - val_loss: 0.2194 - val_acc: 0.7176\n",
            "Epoch 14/50\n",
            "Learning rate:  0.0001\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.2045 - acc: 0.7471 - val_loss: 0.2199 - val_acc: 0.7154\n",
            "Epoch 15/50\n",
            "Learning rate:  0.0001\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.2026 - acc: 0.7517 - val_loss: 0.2164 - val_acc: 0.7246\n",
            "Epoch 16/50\n",
            "Learning rate:  0.0001\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.2011 - acc: 0.7546 - val_loss: 0.2150 - val_acc: 0.7263\n",
            "Epoch 17/50\n",
            "Learning rate:  0.0001\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.2002 - acc: 0.7545 - val_loss: 0.2120 - val_acc: 0.7307\n",
            "Epoch 18/50\n",
            "Learning rate:  0.0001\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1990 - acc: 0.7567 - val_loss: 0.2139 - val_acc: 0.7259\n",
            "Epoch 19/50\n",
            "Learning rate:  0.0001\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1981 - acc: 0.7589 - val_loss: 0.2134 - val_acc: 0.7299\n",
            "Epoch 20/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.2019 - acc: 0.7509 - val_loss: 0.2220 - val_acc: 0.7135\n",
            "Epoch 21/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.1993 - acc: 0.7568 - val_loss: 0.2221 - val_acc: 0.7124\n",
            "Epoch 22/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1976 - acc: 0.7613 - val_loss: 0.2085 - val_acc: 0.7379\n",
            "Epoch 23/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1963 - acc: 0.7625 - val_loss: 0.2138 - val_acc: 0.7295\n",
            "Epoch 24/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.1946 - acc: 0.7642 - val_loss: 0.2076 - val_acc: 0.7390\n",
            "Epoch 25/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1925 - acc: 0.7691 - val_loss: 0.2094 - val_acc: 0.7318\n",
            "Epoch 26/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1910 - acc: 0.7703 - val_loss: 0.2058 - val_acc: 0.7442\n",
            "Epoch 27/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.1891 - acc: 0.7735 - val_loss: 0.2039 - val_acc: 0.7420\n",
            "Epoch 28/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1888 - acc: 0.7747 - val_loss: 0.2105 - val_acc: 0.7305\n",
            "Epoch 29/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1872 - acc: 0.7756 - val_loss: 0.2014 - val_acc: 0.7482\n",
            "Epoch 30/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.1844 - acc: 0.7821 - val_loss: 0.2008 - val_acc: 0.7500\n",
            "Epoch 31/50\n",
            "Learning rate:  0.00025\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1829 - acc: 0.7847 - val_loss: 0.2015 - val_acc: 0.7473\n",
            "Epoch 32/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1903 - acc: 0.7730 - val_loss: 0.2109 - val_acc: 0.7290\n",
            "Epoch 33/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1898 - acc: 0.7734 - val_loss: 0.2138 - val_acc: 0.7311\n",
            "Epoch 34/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.1869 - acc: 0.7777 - val_loss: 0.2060 - val_acc: 0.7376\n",
            "Epoch 35/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.1843 - acc: 0.7815 - val_loss: 0.2117 - val_acc: 0.7339\n",
            "Epoch 36/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1827 - acc: 0.7834 - val_loss: 0.2006 - val_acc: 0.7469\n",
            "Epoch 37/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.1804 - acc: 0.7882 - val_loss: 0.2018 - val_acc: 0.7472\n",
            "Epoch 38/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.1786 - acc: 0.7920 - val_loss: 0.2015 - val_acc: 0.7470\n",
            "Epoch 39/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1777 - acc: 0.7913 - val_loss: 0.1971 - val_acc: 0.7525\n",
            "Epoch 40/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 109ms/step - loss: 0.1761 - acc: 0.7954 - val_loss: 0.2007 - val_acc: 0.7516\n",
            "Epoch 41/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1726 - acc: 0.8038 - val_loss: 0.2003 - val_acc: 0.7521\n",
            "Epoch 42/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1727 - acc: 0.7990 - val_loss: 0.2015 - val_acc: 0.7549\n",
            "Epoch 43/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1711 - acc: 0.8017 - val_loss: 0.1971 - val_acc: 0.7564\n",
            "Epoch 44/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.1692 - acc: 0.8047 - val_loss: 0.1913 - val_acc: 0.7662\n",
            "Epoch 45/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1682 - acc: 0.8073 - val_loss: 0.1905 - val_acc: 0.7658\n",
            "Epoch 46/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.1661 - acc: 0.8106 - val_loss: 0.1961 - val_acc: 0.7660\n",
            "Epoch 47/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1653 - acc: 0.8119 - val_loss: 0.1975 - val_acc: 0.7547\n",
            "Epoch 48/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.1634 - acc: 0.8161 - val_loss: 0.1992 - val_acc: 0.7501\n",
            "Epoch 49/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.1635 - acc: 0.8155 - val_loss: 0.2021 - val_acc: 0.7481\n",
            "Epoch 50/50\n",
            "Learning rate:  0.0005\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.1618 - acc: 0.8171 - val_loss: 0.1905 - val_acc: 0.7636\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}